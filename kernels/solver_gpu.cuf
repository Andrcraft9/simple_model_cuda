module solver_gpu_module

    use kind_module, only: wp8 => SHR_KIND_R8, wp4 => SHR_KIND_R4
    use cudafor
    use kernel_interface_module
    use mpp_sync_module
    use decomposition_module, only: domain_type, domain => domain_data
    use ocean_module, only: ocean_type, ocean_data
    use grid_module, only: grid_type, grid_data

    implicit none
    save
    public

    integer, parameter :: BLOCK_X = 16, BLOCK_Y = 16

contains

subroutine envoke_sw_simple_kernel_gpu(k, it)
    integer, intent(in) :: k
    integer, intent(in) :: it
    type(dim3) :: tBlock, grid

    tBlock = dim3(BLOCK_X, BLOCK_Y, 1)
    grid = dim3(ceiling(real(domain%bnx_end(k) - domain%bnx_start(k) + 1) / tBlock%x),  &
                ceiling(real(domain%bny_end(k) - domain%bny_start(k) + 1) / tBlock%y),  &
                1)

    if (it == 1) then
        print '(A35, I16, I8, I8, I4, I8, I8, I4)', "KERNEL: block, GPU block, grid:", k, tBlock%x, tBlock%y, tBlock%z, grid%x, grid%y, grid%z
    endif

    call sw_simple_kernel_gpu<<<grid, tBlock>>>(domain%bnx_start(k), domain%bnx_end(k), domain%bny_start(k), domain%bny_end(k), ocean_data%ssh%block(k)%field_gpu)

end subroutine

subroutine envoke_sw_simple_sync_gpu(k, sync_parameters)
    integer, intent(in) :: k
    type(sync_parameters_type), intent(in) :: sync_parameters

    integer :: istat

    if (sync_parameters%sync_mode == 0) then
        ocean_data%ssh%block(k)%field = ocean_data%ssh%block(k)%field_gpu
    else if (sync_parameters%sync_mode == 1) then
        ocean_data%ssh%block(k)%field_gpu = ocean_data%ssh%block(k)%field 
    else if (sync_parameters%sync_mode == 2) then
        istat = cudaMemcpy2DAsync(ocean_data%ssh%block(k)%field    (domain%bnx_start(k), domain%bny_start(k)),  &
                                  domain%bnx_end(k) - domain%bnx_start(k) + 1,  &
                                  ocean_data%ssh%block(k)%field_gpu(domain%bnx_start(k), domain%bny_start(k)),  &
                                  domain%bnx_end(k) - domain%bnx_start(k) + 1,  &
                                  domain%bnx_end(k) - domain%bnx_start(k) + 1,  &
                                  domain%bny_end(k) - domain%bny_start(k) + 1,  &
                                  stream=sync_gpu_streams(k))
    else if (sync_parameters%sync_mode == 3) then
        istat = cudaMemcpy2DAsync(ocean_data%ssh%block(k)%field_gpu(domain%bnx_start(k), domain%bny_start(k)),  &
                                  domain%bnx_end(k) - domain%bnx_start(k) + 1,  &
                                  ocean_data%ssh%block(k)%field    (domain%bnx_start(k), domain%bny_start(k)),  &
                                  domain%bnx_end(k) - domain%bnx_start(k) + 1,  &
                                  domain%bnx_end(k) - domain%bnx_start(k) + 1,  &
                                  domain%bny_end(k) - domain%bny_start(k) + 1,  &
                                  stream=sync_gpu_streams(k))
    endif
end subroutine 

attributes(global) subroutine sw_simple_kernel_gpu(nx_start, nx_end, ny_start, ny_end, ssh)
    integer, intent(in), value :: nx_start, nx_end, ny_start, ny_end
    real(wp8), intent(inout) :: ssh(nx_start:nx_end, ny_start:ny_end)

    integer, value :: i, j

    i = (blockIdx%x-1)*blockDim%x + threadIdx%x + (nx_start - 1)
    j = (blockIdx%y-1)*blockDim%y + threadIdx%y + (ny_start - 1)
    
    if (i <= nx_end .and. j <= ny_end) then
        ssh(i,j) = ssh(i,j) + 1.0d0
     endif
end subroutine

subroutine envoke_sw_update_ssh_kernel_gpu(k, it)
    integer, intent(in) :: k
    integer, intent(in) :: it
    type(dim3) :: tBlock, grid

    tBlock = dim3(BLOCK_X, BLOCK_Y, 1)
    grid = dim3(ceiling(real(domain%bnx_end(k) - domain%bnx_start(k) + 1) / tBlock%x),  &
                ceiling(real(domain%bny_end(k) - domain%bny_start(k) + 1) / tBlock%y),  &
                1)

    if (it == 1) then
        print '(A35, I16, I8, I8, I4, I8, I8, I4)', "KERNEL: block, GPU block, grid:", k, tBlock%x, tBlock%y, tBlock%z, grid%x, grid%y, grid%z
    endif

    call sw_update_ssh_kernel_gpu<<<grid, tBlock>>>(domain%bnx_start(k), domain%bnx_end(k), domain%bny_start(k), domain%bny_end(k),  &
                                                    1.0d0,  &
                                                    grid_data%lu %block(k)%field_gpu,  &
                                                    grid_data%dxt%block(k)%field_gpu,  &
                                                    grid_data%dyt%block(k)%field_gpu,  &
                                                    grid_data%hhu%block(k)%field_gpu,  &
                                                    grid_data%hhv%block(k)%field_gpu,  &
                                                    ocean_data%ssh   %block(k)%field_gpu,  &
                                                    ocean_data%ubrtr %block(k)%field_gpu,  &
                                                    ocean_data%vbrtr %block(k)%field_gpu)


end subroutine

subroutine envoke_sw_update_ssh_sync_gpu(k, sync_parameters)
    integer, intent(in) :: k
    type(sync_parameters_type), intent(in) :: sync_parameters

    integer :: istat

    if (sync_parameters%sync_mode == 0) then
        ocean_data%ssh%block(k)%field = ocean_data%ssh%block(k)%field_gpu
    else if (sync_parameters%sync_mode == 1) then
        ocean_data%ssh%block(k)%field_gpu = ocean_data%ssh%block(k)%field 
    else if (sync_parameters%sync_mode == 2) then
        istat = cudaMemcpy2DAsync(ocean_data%ssh%block(k)%field    (domain%bnx_start(k), domain%bny_start(k)),  &
                                  domain%bnx_end(k) - domain%bnx_start(k) + 1,  &
                                  ocean_data%ssh%block(k)%field_gpu(domain%bnx_start(k), domain%bny_start(k)),  &
                                  domain%bnx_end(k) - domain%bnx_start(k) + 1,  &
                                  domain%bnx_end(k) - domain%bnx_start(k) + 1,  &
                                  domain%bny_end(k) - domain%bny_start(k) + 1,  &
                                  stream=sync_gpu_streams(k))
    else if (sync_parameters%sync_mode == 3) then
        istat = cudaMemcpy2DAsync(ocean_data%ssh%block(k)%field_gpu(domain%bnx_start(k), domain%bny_start(k)),  &
                                  domain%bnx_end(k) - domain%bnx_start(k) + 1,  &
                                  ocean_data%ssh%block(k)%field    (domain%bnx_start(k), domain%bny_start(k)),  &
                                  domain%bnx_end(k) - domain%bnx_start(k) + 1,  &
                                  domain%bnx_end(k) - domain%bnx_start(k) + 1,  &
                                  domain%bny_end(k) - domain%bny_start(k) + 1,  &
                                  stream=sync_gpu_streams(k))
    endif
end subroutine 

attributes(global) subroutine sw_update_ssh_kernel_gpu(nx_start, nx_end, ny_start, ny_end,  &
                                                   tau, lu, dx, dy, hhu, hhv, ssh, ubrtr, vbrtr)

  integer, intent(in), value :: nx_start, nx_end, ny_start, ny_end
  real(wp8), intent(in), value :: tau
  real(wp8), intent(in) :: lu(nx_start:nx_end, ny_start:ny_end)
  real(wp8), intent(in) :: dx(nx_start:nx_end, ny_start:ny_end),   &
                           dy(nx_start:nx_end, ny_start:ny_end)
  real(wp8), intent(in) :: hhu(nx_start:nx_end, ny_start:ny_end),  &
                           hhv(nx_start:nx_end, ny_start:ny_end)
  real(wp8), intent(in) :: ubrtr(nx_start:nx_end, ny_start:ny_end),  &
                           vbrtr(nx_start:nx_end, ny_start:ny_end)
  real(wp8), intent(inout) :: ssh(nx_start:nx_end, ny_start:ny_end)

  integer, value :: m, n

  m = (blockIdx%x-1)*blockDim%x + threadIdx%x + (nx_start + 1 - 1)
  n = (blockIdx%y-1)*blockDim%y + threadIdx%y + (ny_start + 1 - 1)
  
  if (m <= nx_end - 1 .and. n <= ny_end - 1) then
      if (lu(m,n)>0.5) then
        ssh(m,n) = ssh(m,n) + 2.0d0*tau*(  &
        - ( ubrtr(m,n)*hhu(m,n)*dy(m,n) - ubrtr(m-1,n)*hhu(m-1,n)*dy(m-1,n)             &
            + vbrtr(m,n)*hhv(m,n)*dx(m,n) - vbrtr(m,n-1)*hhv(m,n-1)*dx(m,n-1) )/(dx(m,n)*dy(m,n))  )
      endif
  endif

end subroutine

end module solver_gpu_module